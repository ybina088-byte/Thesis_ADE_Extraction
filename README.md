Perfect ğŸ‘ Letâ€™s draft a **clear and professional `README.md`** for your GitHub repository. This will explain your thesis project, its purpose, datasets, methods, and how others can reproduce your results.

Hereâ€™s a first version:

---

# Thesis\_ADE\_Extraction

## ğŸ“– Project Overview

This repository contains the implementation for my MSc Thesis:
**"Interpretable Extraction of Adverse Drug Events (ADEs): Comparing Biomedical Transformers and Large Language Models"**

The project investigates how **biomedical transformer models** (BioBERT, PubMedBERT) compare with **large language models** (BioGPT, GPT-based prompting) in extracting **Adverse Drug Events (ADEs)** from benchmark datasets.

---

## ğŸ¯ Research Question

**RQ2:**
How do biomedical transformer models (BioBERT, PubMedBERT) compare with Large Language Models (e.g., BioGPT, GPT-based prompting) in extracting ADEs from benchmark datasets (CADEC, SMM4H)?
Can LLMs provide competitive or superior results in few-shot and zero-shot settings?

---

## ğŸ“Œ Objectives

1. Implement and evaluate baseline transformer models (BioBERT, PubMedBERT) for:

   * **ADE Named Entity Recognition (NER)** â€“ CADEC dataset
   * **ADE Normalization/Classification** â€“ SMM4H dataset
2. Investigate LLM-based methods (prompting, few-shot, and fine-tuning BioGPT).
3. Compare performance across datasets using standardized metrics.
4. Conduct error analysis of transformer vs. LLM performance.
5. *(Optional)* Explore interpretability (attention visualization, SHAP).

---

## ğŸ“‚ Repository Structure

```
Thesis_ADE_Extraction/
â”‚
â”œâ”€â”€ configs/                     # Config files
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original datasets
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ hf_cadec_reduced/    # HuggingFace-format CADEC
â”‚   â”‚   â””â”€â”€ hf_smm4h_subtask3/   # HuggingFace-format SMM4H
â”‚
â”œâ”€â”€ figures/                     # Plots and visualizations
â”œâ”€â”€ logs/                        # Training logs
â”œâ”€â”€ models/                      # Saved transformer/LLM models
â”œâ”€â”€ predictions/                 # Model outputs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/                  # Model modules
â”‚   â”‚   â”œâ”€â”€ llm_prompting.py     # Few-shot/zero-shot prompting (LLMs)
â”‚   â”‚   â”œâ”€â”€ relation_extraction.py # Drugâ€“ADE relation extraction
â”‚   â”‚   â””â”€â”€ transformer_ner.py   # Transformer baseline (NER)
â”‚   â”œâ”€â”€ data_preprocessing.py    # Preprocess raw datasets
â”‚   â”œâ”€â”€ dataset_loader.py        # Load into HF format
â”‚   â”œâ”€â”€ dataset_sanity_check.py  # Verify label/token consistency
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation utilities
â”‚   â”œâ”€â”€ tokenizer_utils.py       # Align labels with tokens
â”‚   â”œâ”€â”€ train_cadec_ner.py       # Train CADEC NER baseline
â”‚   â””â”€â”€ train_smm4h_classification.py # Train SMM4H classification baseline
â”‚
â”œâ”€â”€ thesis-paper/                # Drafts and reports
â”œâ”€â”€ environment.yml              # Conda environment
â”œâ”€â”€ README.md                    # Project description
â””â”€â”€ .gitignore                   # Ignore large/log files
```

---

## âš™ï¸ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/<your-username>/Thesis_ADE_Extraction.git
cd Thesis_ADE_Extraction
conda env create -f environment.yml
conda activate ade-thesis
```

---

## ğŸ“Š Datasets

* **CADEC** â€“ Consumer Adverse Drug Effect Corpus (NER, entity-level ADE extraction).
* **SMM4H Subtask 3** â€“ Social Media Mining for Health dataset (ADE normalization/classification).

Both are preprocessed into **HuggingFace format** in `data/processed/`.

---

## ğŸš€ Training & Evaluation

### 1. CADEC (NER with BioBERT)

```bash
python src/train_cadec_ner.py
```

### 2. SMM4H (Classification with BioBERT)

```bash
python src/train_smm4h_classification.py
```

Logs and model checkpoints are saved in `logs/` and `models/`.

---

## ğŸ“ˆ Results (so far)

* **CADEC NER (BioBERT):** strong micro-F1 â‰ˆ **0.91** (baseline established).
* **SMM4H Classification (BioBERT, 10 epochs):** accuracy â‰ˆ **85%**, macro-F1 â‰ˆ **0.42**.

Next: PubMedBERT baselines + LLM prompting.

---

## ğŸ Roadmap

* [x] Baseline transformers (BioBERT on CADEC + SMM4H)
* [ ] PubMedBERT baselines
* [ ] LLM prompting experiments (GPT, BioGPT)
* [ ] Relation extraction module
* [ ] Error analysis & interpretability
* [ ] Write-up & defense preparation

---

## ğŸ“œ Expected Contributions

* Systematic comparison of **biomedical transformers vs. LLMs** for pharmacovigilance.
* Insights into whether **LLMs can replace or complement** domain-specific models.
* Transparent and interpretable ADE extraction pipeline.

---

ğŸ‘‰ This is a clean, professional README. You can update the **Results** section as you run more experiments.

Would you like me to also include **example outputs** (like sample predictions from CADEC/SMM4H) in the README so it looks more illustrative?
